{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2024-06-23T21:55:39.878249Z",
          "start_time": "2024-06-23T21:55:39.870840Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "initial_id",
        "outputId": "36fd9a6e-c4cc-4e92-e28e-314b1451b93f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!\n",
            "Current GPU Device: 0\n",
            "GPU Properties: _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15102MB, multi_processor_count=40)\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from random import random\n",
        "import random\n",
        "from preprocess_data import PreprocessData\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "# import torchvision\n",
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print('CUDA is available!')\n",
        "    # Get the index of the current GPU device\n",
        "    print('Current GPU Device:', torch.cuda.current_device())\n",
        "    # Get properties of the current GPU\n",
        "    print('GPU Properties:', torch.cuda.get_device_properties(torch.cuda.current_device()))\n",
        "else:\n",
        "    print('CUDA is not available.')\n",
        "\n",
        "torch.manual_seed(1)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "EPOCH = 30\n",
        "BATCH_SIZE = 128\n",
        "LR = 0.001\n",
        "CONTEXT_SIZE = 2\n",
        "EMBEDDING_DIM = 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "100%|██████████| 50/50 [00:57<00:00,  1.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words: 945357\n",
            "Vocabulary size: 41380\n",
            "Example of word to index: [('peanut', 0), ('unreasonable', 1), ('vilest', 2), ('underscore', 3), ('waldorf', 4)]\n",
            "Example of index to word: [(0, 'peanut'), (1, 'unreasonable'), (2, 'vilest'), (3, 'underscore'), (4, 'waldorf')]\n",
            "Number of context-target pairs: 945353\n",
            "Example of context-target pair: tensor([23075, 27234, 24931, 25993], device='cuda:0') - tensor([14785, 24931, 25993,  ..., 23259,   315, 16254], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "## Preprocess Data ##\n",
        "p = PreprocessData()\n",
        "p.download_data(from_id=1513, limit=50)\n",
        "words = p.tokenize(remove_stop_words=True)\n",
        "print(f'Number of words: {len(words)}')\n",
        "\n",
        "vocab = set(words)\n",
        "print(f'Vocabulary size: {len(vocab)}')\n",
        "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
        "print(f'Example of word to index: {list(word_to_idx.items())[:5]}')\n",
        "idx_to_word = {i: word for word, i in word_to_idx.items()}\n",
        "print(f'Example of index to word: {list(idx_to_word.items())[:5]}')\n",
        "\n",
        "## Context-Target pairs ##\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(CONTEXT_SIZE, len(words) - CONTEXT_SIZE):\n",
        "    context = (\n",
        "            [word_to_idx[words[i - j]] for j in range(1,CONTEXT_SIZE+1)]\n",
        "            + [word_to_idx[words[i + j]] for j in range(1,CONTEXT_SIZE+1)]\n",
        "    )\n",
        "    target = word_to_idx[words[i]]\n",
        "    X.append(context)\n",
        "    Y.append(target)\n",
        "X = torch.tensor(X).to(device)\n",
        "Y = torch.tensor(Y).to(device)\n",
        "    # data.append((context, target))\n",
        "print(f'Number of context-target pairs: {len(X)}')\n",
        "print(f'Example of context-target pair: {X[0]} - {Y}')\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-23T21:55:57.658141Z",
          "start_time": "2024-06-23T21:55:41.699671Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a222e8ed3e7e7d7",
        "outputId": "d5510d65-2ccc-4e82-9367-ba22f579cde0"
      },
      "id": "8a222e8ed3e7e7d7"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "outputs": [],
      "source": [
        "## Model ##\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "        super(Model, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim).to(device)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size).to(device)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs)\n",
        "        embeds = torch.sum(embeds, dim=1, keepdim=False)\n",
        "        out = self.linear(embeds)\n",
        "        return F.log_softmax(out, dim=1)  # softmax compute log probability\n",
        "\n",
        "\n",
        "\n",
        "model = Model(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "\n",
        "class SimpleIterableDataset(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, X, Y):\n",
        "        super(SimpleIterableDataset).__init__()\n",
        "        self.data = []\n",
        "        for i in range(len(X)):\n",
        "            self.data.append( (Y[i], X[i]) )\n",
        "        random.shuffle(self.data)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.data)\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-23T21:55:57.665152Z",
          "start_time": "2024-06-23T21:55:57.659365Z"
        },
        "id": "6a26cff78cf34c2e"
      },
      "id": "6a26cff78cf34c2e"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "outputs": [],
      "source": [
        "ds = SimpleIterableDataset(X, Y)\n",
        "dl = torch.utils.data.DataLoader(ds, batch_size = BATCH_SIZE)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-23T21:55:58.098379Z",
          "start_time": "2024-06-23T21:55:57.665411Z"
        },
        "id": "16124a7d566951f0"
      },
      "id": "16124a7d566951f0"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 | Loss: 478.91 | Time: 34.39s\n",
            "Epoch 2/30 | Loss: 423.02 | Time: 34.09s\n",
            "Epoch 3/30 | Loss: 403.39 | Time: 34.23s\n",
            "Epoch 4/30 | Loss: 390.14 | Time: 34.36s\n",
            "Epoch 5/30 | Loss: 379.88 | Time: 34.45s\n",
            "Epoch 6/30 | Loss: 371.36 | Time: 34.52s\n",
            "Epoch 7/30 | Loss: 363.99 | Time: 34.55s\n",
            "Epoch 8/30 | Loss: 357.44 | Time: 34.56s\n",
            "Epoch 9/30 | Loss: 351.51 | Time: 34.60s\n",
            "Epoch 10/30 | Loss: 346.09 | Time: 34.63s\n",
            "Epoch 11/30 | Loss: 341.08 | Time: 34.65s\n",
            "Epoch 12/30 | Loss: 336.41 | Time: 34.67s\n",
            "Epoch 13/30 | Loss: 332.06 | Time: 34.66s\n",
            "Epoch 14/30 | Loss: 327.97 | Time: 34.66s\n",
            "Epoch 15/30 | Loss: 324.12 | Time: 34.66s\n",
            "Epoch 16/30 | Loss: 320.49 | Time: 34.66s\n",
            "Epoch 17/30 | Loss: 317.06 | Time: 34.67s\n",
            "Epoch 18/30 | Loss: 313.81 | Time: 34.66s\n",
            "Epoch 19/30 | Loss: 310.73 | Time: 34.66s\n",
            "Epoch 20/30 | Loss: 307.80 | Time: 34.64s\n",
            "Epoch 21/30 | Loss: 305.03 | Time: 34.62s\n",
            "Epoch 22/30 | Loss: 302.39 | Time: 34.62s\n",
            "Epoch 23/30 | Loss: 299.89 | Time: 34.61s\n",
            "Epoch 24/30 | Loss: 297.50 | Time: 34.60s\n",
            "Epoch 25/30 | Loss: 295.24 | Time: 34.62s\n",
            "Epoch 26/30 | Loss: 293.08 | Time: 34.63s\n",
            "Epoch 27/30 | Loss: 291.04 | Time: 34.64s\n",
            "Epoch 28/30 | Loss: 289.08 | Time: 34.65s\n",
            "Epoch 29/30 | Loss: 287.23 | Time: 34.65s\n",
            "Epoch 30/30 | Loss: 285.46 | Time: 34.65s\n"
          ]
        }
      ],
      "source": [
        "## Training ##\n",
        "\n",
        "losses = []\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "    for labels, features in dl:\n",
        "        labels = labels.to(device)\n",
        "        features = features.to(device)\n",
        "        model.zero_grad()\n",
        "        log_probs = model(features)\n",
        "        loss = loss_function(log_probs, labels)\n",
        "        loss /= len(labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss\n",
        "\n",
        "    losses.append(total_loss)\n",
        "    print(f'Epoch {epoch+1}/{EPOCH} | Loss: {total_loss:.2f} | Time: {time.time() - start:.2f}s')\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-23T22:08:08.142697Z",
          "start_time": "2024-06-23T21:55:58.099674Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a727a3721d0f180b",
        "outputId": "59733a7b-a447-480c-e8a0-e115b34361ed"
      },
      "id": "a727a3721d0f180b"
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "outputs": [],
      "source": [
        "    # COSINE SIMILARITY\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "9af0b77ad8f580bf"
      },
      "id": "9af0b77ad8f580bf"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "arr = ['king', 'queen', 'man', 'woman', 'castle', 'lion', 'cat', 'pet']\n",
        "\n",
        "dict_vector = dict()\n",
        "for w in arr:\n",
        "  dict_vector[w] = model.embeddings.weight[word_to_idx[w]].detach().cpu().numpy().reshape(1, -1)\n",
        "\n",
        "\n",
        "res = cosine_similarity(dict_vector['lion'], dict_vector['lion'])\n",
        "print(f'Similarity between lion and lion: {res[0][0]:.2f}')\n",
        "\n",
        "res = cosine_similarity(dict_vector['lion'], dict_vector['cat'])\n",
        "print(f'Similarity between lion and cat: {res[0][0]:.2f}')\n",
        "\n",
        "\n",
        "res = cosine_similarity(dict_vector['lion'], dict_vector['pet'])\n",
        "print(f'Similarity between lion and pet: {res[0][0]:.2f}')\n",
        "\n",
        "res = cosine_similarity(dict_vector['king'], dict_vector['queen'])\n",
        "print(f'Similarity between king and queen: {res[0][0]:.2f}')\n",
        "\n",
        "king = dict_vector['king'].reshape(-1)\n",
        "man = dict_vector['man'].reshape(-1)\n",
        "woman = dict_vector['woman'].reshape(-1)\n",
        "new_vector = king - man + woman\n",
        "res = cosine_similarity(dict_vector['queen'], new_vector.reshape(1,-1))\n",
        "print(f'Similarity between queen and new_vector: {res[0][0]:.2f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWN04R9CxtU7",
        "outputId": "4621c4ff-b6de-4205-e5f7-afb77b702609"
      },
      "id": "uWN04R9CxtU7",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between lion and lion: 1.00\n",
            "Similarity between lion and cat: 0.17\n",
            "Similarity between lion and pet: 0.15\n",
            "Similarity between king and queen: 0.25\n",
            "Similarity between queen and new_vector: 0.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lrXLUcgHyGQY"
      },
      "id": "lrXLUcgHyGQY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}